# Anamnesis â€“ AI Patient Intake & Clinical Memory

Anamnesis is an AI-powered **patient intake assistant** and **clinical memory** system.

- Patients first chat with an intake bot that asks clinically inspired questions.
- A large language model converts the transcript into a **structured intake note** (chief complaint, symptoms, medications, allergies, history, red flags, etc.).
- Key information is stored and indexed in **PostgreSQL + pgvector**.
- Doctors can then ask **free-text questions** about a patient and get grounded answers with citations, using RAG (Retrieval-Augmented Generation).

> âš ï¸ **Disclaimer**  
> This is a **research / portfolio project**. It is **not a medical device** and must **not** be used for real patient care or clinical decision making.

---

## âœ¨ Features

### ğŸ—£ Multi-stage patient intake

The intake assistant walks through a structured, clinically inspired flow:

1. **Chief complaint** â€“ what brings the patient in.
2. **Symptom details** â€“ onset, course, location, severity, etc.
3. **Safety checks** â€“ potential red-flag symptoms.
4. **History** â€“ past medical history, medications, allergies, family & social history.
5. **Wrap-up** â€“ anything else the patient wants the doctor to know.

Under the hood this is implemented as:

- `IntakeAgent` â€“ a rule-based, stage-based agent.
- `IntakeState` â€“ keeps track of stage, turns, and completion.
- `Utterance` rows in Postgres â€“ each message (patient / assistant) is persisted.

---

### ğŸ§  LLM-based structured intake note

After the intake conversation completes:

1. The full transcript is assembled from `Utterance`s.
2. A large language model (LLaMA 3.3 70B via **Groq**, OpenAI-compatible API) is prompted to output **strict JSON**.
3. The JSON is validated against a Pydantic v2 schema: `StructuredIntakeModel`.
4. The validated record is stored as **JSONB** in the `structured_intake` table.

The structured note includes:

- `chief_complaint`
- `symptoms` (with onset, duration, location, character, severity, associated symptoms, red flags)
- `medications`
- `allergies`
- `past_medical_history`, `family_history`, `social_history`
- `red_flags`
- `patient_goals`, `other_notes`

---

### ğŸ“š RAG over patient history (Postgres + pgvector)

To support doctor questions:

1. **Chunking**
   - Text chunks are built from:
     - structured intake fields (symptoms, meds, allergies, histories, red flags, goals)
     - merged patient utterances
     - merged assistant questions.
2. **Embeddings**
   - Chunks are embedded with `sentence-transformers/all-MiniLM-L6-v2` (384-dim).
3. **Vector store**
   - Embeddings are stored in the `patient_chunks` table using **pgvector**.
4. **Retrieval + QA**
   - For each doctor question:
     - embed the question,
     - run a pgvector similarity search over that patientâ€™s chunks,
     - build a context prompt with the top-k chunks,
     - call the LLM with strict â€œonly answer from contextâ€ instructions,
     - return an answer plus the chunks used (citations like `[chunk 1]`).

---

### ğŸ§© End-to-end app (backend + frontend)

**Backend**

- Python + FastAPI API
- PostgreSQL + pgvector (Docker Compose)
- SQLAlchemy 2.x ORM
- Pydantic v2 (`BaseModel`, `BaseSettings`)
- LLM client abstraction (`LLMClient` / `OpenAILLMClient`) configured for Groq

**Frontend**

- React + TypeScript (Vite)
- Tailwind CSS for styling
- Single-page layout:
  - **Left:** â€œStep 1 â€“ Patient Intakeâ€ (chat UI + stage progress).
  - **Right:** â€œStep 2 â€“ Doctor Viewâ€ (structured summary + QA with supporting snippets).

---

## ğŸ— Architecture Overview

**Backend modules**

- `app/config.py` â€“ settings (DB URL, embedding dimension, LLM key, base URL, model name).
- `app/db.py` â€“ SQLAlchemy engine, session factory, Base, pgvector type.
- `app/models.py` â€“ ORM models:
  - `Patient`
  - `Encounter`
  - `Utterance`
  - `StructuredIntake`
  - `PatientChunk`
- `app/intake/`
  - `schema.py` â€“ `StructuredIntakeModel` + nested types (`Symptom`, `Medication`, `Allergy`).
  - `stages.py` â€“ `IntakeStage` enum.
  - `state.py` â€“ `IntakeState`, `IntakeTurn`.
  - `agent.py` â€“ rule-based intake agent.
  - `summarizer.py` â€“ heuristic + LLM-based builders for `StructuredIntakeModel`.
- `app/llm/`
  - `client.py` â€“ `LLMClient` interface and `OpenAILLMClient` that talks to Groq via OpenAI-compatible API (using `OPENAI_BASE_URL`).
- `app/services/`
  - `intake_session.py` â€“ `IntakeSessionService`: orchestrates patient/encounter creation, intake agent, and utterance persistence; `init_db()` to create tables and pgvector extension.
- `app/rag/`
  - `embeddings.py` â€“ SentenceTransformer wrapper (`all-MiniLM-L6-v2`).
  - `indexer.py` â€“ builds chunks and inserts into `patient_chunks`.
  - `retriever.py` â€“ pgvector similarity search for a given patient + query.
  - `qa.py` â€“ RAG-style QA over retrieved chunks using the LLM.
- `app/api/`
  - `schemas.py` â€“ FastAPI request/response models.
  - `routes.py` â€“ API endpoints (intake + structured note + QA).
- `app/main.py` â€“ FastAPI app, startup hook (`init_db`), router mounting.

**Frontend**

- `frontend/src/App.tsx`
  - Left pane: patient intake chat (with stage progress and status chips).
  - Right pane: structured summary card + doctor QA area.
- `frontend/src/main.tsx`
  - React entry point.
- `frontend/src/index.css`
  - Tailwind base/components/utilities + dark theme base styles.
- `tailwind.config.cjs`, `postcss.config.cjs` â€“ Tailwind configuration.

---